{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rappel Google Colab\n",
    "\n",
    "Tout d'abord, sélectionnez l'option GPU de Colab avec *Edit > Notebook settings* et sélectionner GPU comme Hardware accelerator. \n",
    "Installer ensuite deeplib avec la commande suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ulaval-damas/glo4030-labs.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 3: Optimisation\n",
    "\n",
    "## Partie 1: Fonctions d'optimisation\n",
    "\n",
    "Dans cette section, vous testerez différentes fonctions d'optimisation et observerez leurs effets sur l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import poutyne as pt\n",
    "\n",
    "from deeplib.history import History\n",
    "from deeplib.datasets import train_valid_loaders, load_cifar10\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from deeplib.net import CifarNet\n",
    "\n",
    "from deeplib.datasets import train_valid_loaders, load_mnist, load_cifar10\n",
    "from deeplib.training import train, validate_ranking, test\n",
    "from deeplib.visualization import show_2d_function, show_optimization, show_worst, show_random, show_best\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Un exemple jouet\n",
    "\n",
    "On va commencer par explorer les effets des variantes de SGD avec un exemple jouet. L'exemple jouet va consister en une régression linéaire simple en 2 dimensions avec laquelle on sera en mesure de visualiser l'impact des différentes variantes de SGD. En effet, dans cette section, on va jouer avec trois paramètres de SGD: le taux d'apprentissage, le momentum et l'accélération de Nesterov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialisations notre jeu de données jouet qui va contenir seulement 3 points en 2 dimensions ainsi que 3 valeurs à régresser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1,1],[0,-1],[2,.5]], dtype=torch.float32)\n",
    "y = torch.tensor([[-1.], [3], [2]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors d'une régression linéaire, on souhaite trouver des poids $w^*$ qui minimise pour chaque exemple $(x_i, y_i)$ la perte quadratique entre $x_i \\cdot w$ et $y_i$. Mathématiquement, voici la fonction que l'on souhaite optimiser:\n",
    "$$F(w) = \\frac{1}{n} \\sum_{i=1}^{n} (x_i \\cdot w - y_i)^2$$\n",
    "On souhaite donc trouver les poids optimaux $w^*$ qui minimise $F(w)$.\n",
    "$$w^* = \\text{argmin}_w F(w)$$\n",
    "La cellule ci-dessous est cette fonction objectif en fonction des paramètres $w$ que l'on souhaite trouver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(w):\n",
    "    return torch.mean((x @ w - y) ** 2, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous vous en rappelez peut-être, la solution d'une régression linéaire a une forme analytique qui est la suivante.\n",
    "$$w^* = (X^TX)^{-1}X^TY$$\n",
    "La cellule ci-dessous trouve la solution pour notre problème jouet en utilisant cette formule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_opt = torch.inverse(x.T @ x) @ x.T @ y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser la fonction `show_2d_function` de la librairie `deeplib`. La librairie `deeplib` est une libraire écrite spécialement pour les notebook de ce cours. La fonction `show_2d_function` permet de visualiser notre fonction objectif avec des courbes de niveau. Les deux axes correspondent à différentes valeurs pour les 2 poids respectifs de $w$ pour notre régression linéaire en 2 dimensions. La couleur des courbes de niveau donne la valeur de la fonction objectif. L'étoile rouge correspond à $w^*$, notre valeur optimale des poids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_2d_function(objective_function, optimal=w_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les prochaines cellules définissent deux fonctions. \n",
    "\n",
    "La première fonction se charge d'optimiser notre fonction objectif à la manière des réseaux de neurones en utilisant l'optimiseur SGD de PyTorch. La fonction retourne l'historique des poids $w$ de chaque itération ainsi que l'historique des valeurs de perte. Des commentaires dans cette fonction ont été laissés afin que vous puissiez comprendre le déroulement de l'optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(learning_rate, momentum, nesterov, nb_iter=20):\n",
    "    \"\"\"\n",
    "    Optimise la fonction objectif à la manière de PyTorch avec l'optimiseur SGD.\n",
    "    \n",
    "    Args:\n",
    "        learning_rate: Le taux d'apprentissage.\n",
    "        momentum: La valeur du momentum.\n",
    "        nesterov: Si l'accélération de Nesterov est désirée.\n",
    "        nb_iter: Le nombre d'itérations effectué.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple `(w_history, loss_history)` où `w_history` correspond à \n",
    "        l'historique des poids lors de l'optimisation et `loss_history`\n",
    "        correspond à l'historique de la valeur de la fonction objectif \n",
    "        ou fonction de perte dans le cadre des réseaux de neurones.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # Notre réseau: une couche linéaire sans biais. Essentiellement, 2 poids.\n",
    "    neuron = nn.Linear(2, 1, bias=False)\n",
    "    \n",
    "    # La fonction de perte quadratique.\n",
    "    loss_function = nn.MSELoss()\n",
    "    \n",
    "    # Initialise l'optimiseur SGD\n",
    "    optimizer = optim.SGD(neuron.parameters(), lr=learning_rate, momentum=momentum, nesterov=nesterov)\n",
    "\n",
    "    # À la différence des réseaux de neurones, on ne divise pas en epochs\n",
    "    # et en batchs étant donné que notre jeu de données contient seulement\n",
    "    # 3 points et que notre problème est convexe et donc résoluble avec une\n",
    "    # simple descente de gradient. On fera donc un certain nombre d'itérations\n",
    "    # pour trouver la solution du problème. On pourrait voir une itération comme \n",
    "    # un epoch avec une seule batch contenant le jeu de données entier.\n",
    "    # Pour chaque itération, on y va à \n",
    "    # la manière des réseaux de neurones:\n",
    "    # - On effectue une prédiction;\n",
    "    # - On calcule notre perte;\n",
    "    # - On fait la rétropropagation (backpropagation) via la méthode backward();\n",
    "    # - On met à jour les poids avec l'optimiseur.\n",
    "    w_history = []\n",
    "    loss_history = []\n",
    "    for t in range(nb_iter):\n",
    "        y_pred = neuron(x)\n",
    "        loss = loss_function(y_pred, y)         \n",
    "        w_history.append(neuron.weight.squeeze(0).detach().clone().numpy())\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    return w_history, loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La deuxième fonction trace des graphiques permettant de visualiser l'optimisation effectuée par la première fonction. La fonction ne fait qu'appeler la fonction `show_optimization` définie dans `deeplib` en lui passant en paramètre les historiques retournées par la fonction d'optimisation, la fonction objectif ainsi que les paramètres optimaux que nous avons calculés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_objective_optimization(w_history, loss_history, **kwargs):\n",
    "    return show_optimization(w_history, loss_history, objective_function, optimal=w_opt, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va utiliser ces deux fonctions pour pouvoir visualiser l'impact de trois paramètres de SGD: le taux d'apprentissage, le momentum et l'accélération de Nesterov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.3\n",
    "momentum = 0\n",
    "nesterov = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisons maintenant notre fonction avec les valeurs ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_history, loss_history = optimize(learning_rate, momentum, nesterov)\n",
    "show_objective_optimization(w_history, loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit qu'après 10 itérations, l'optimisation a relativement convergé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices\n",
    "\n",
    "Pour les exercices ci-dessous, vous pouvez utiliser des fonctions comme [`numpy.linspace`](https://numpy.org/doc/stable/reference/generated/numpy.linspace.html), [`numpy.logspace`](https://numpy.org/doc/stable/reference/generated/numpy.logspace.html) ou [`numpy.geomspace`](https://numpy.org/doc/stable/reference/generated/numpy.geomspace.html) permettant d'obtenir une liste de valeurs à tester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Testez différentes valeurs entre 0 et 1 du taux d'apprentissage en complétant la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "momentum = 0.\n",
    "nesterov = False\n",
    "for learning_rate in [...]: # TODO à compléter avec différentes valeurs\n",
    "    w_history, loss_history = optimize(learning_rate, momentum, nesterov)\n",
    "    show_objective_optimization(w_history, loss_history, title=f\"Learning rate: {learning_rate:.2g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Testez différentes valeurs entre 0 et 1 pour le momentum en complétant la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.3\n",
    "nesterov = False\n",
    "for momentum in [...]: # TODO à compléter avec différentes valeurs\n",
    "    w_history, loss_history = optimize(learning_rate, momentum, nesterov)\n",
    "    show_objective_optimization(w_history, loss_history, title=f\"Momentum: {momentum:.2g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Testez différentes valeurs entre 0 et 1 pour le momentum avec l'accélération de Nesterov en complétant la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.3\n",
    "nesterov = True\n",
    "for momentum in [...]: # TODO à compléter avec différentes valeurs\n",
    "    w_history, loss_history = optimize(learning_rate, momentum, nesterov)\n",
    "    show_objective_optimization(w_history, loss_history, title=f\"Momentum: {momentum:.2g} avec Nesterov\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Que pouvons-nous remarquer sur l'impact du taux d'apprentissage sur l'optimisation?\n",
    "- Que pouvons-nous remarquer sur l'impact du momentum sur l'optimisation?\n",
    "- Que pouvons-nous remarquer sur l'impact de l'accélération de Nesterov sur l'optimisation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Un exemple plus près de la réalité\n",
    "\n",
    "Testons maintenant différents optimiseurs sur un vrai réseau de neurones avec un vrai jeu de données. Comme dans les labos précédents, on utilise le jeu de données CIFAR10 avec un simple réseau à convolution.\n",
    "\n",
    "Initialisons le jeu de données et quelques hyperparamètres qui vont rester constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train, cifar_test = load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.01\n",
    "n_epoch = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le reste de ce notebook et dans les prochains laboratoires, nous allons utiliser la fonction `train` qui est définie dans la librairie `deeplib`. La fonction utilise la librairie [Poutyne](https://poutyne.org). Comme vu dans le laboratoire 1, Poutyne nous donne un meilleur affichage de l'évolution de l'entraînement comparativement à notre boucle d'entraînement personnalisée que nous avions fait à la main. Comme on va le voir plus loin, l'utilisation de Poutyne implique nous allons devoir utiliser des callbacks de Poutyne pour les horaires d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice\n",
    "\n",
    " - Comparez trois différentes stratégies d'optimisation:\n",
    "1. [SGD](http://pytorch.org/docs/master/optim.html#torch.optim.SGD)\n",
    "2. SGD + Momentum accéléré de Nesterov\n",
    "3. [Adam](http://pytorch.org/docs/master/optim.html#torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par l'entraîner avec SGD (sans momentum ni accélération de Nesterov)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNet()\n",
    "model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "history_sgd = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)\n",
    "history_sgd.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(model, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Complétez cette cellule pour entraîner avec SGD + Momentum accéléré de Nesterov. Utilisez un momentum de 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNet()\n",
    "model.cuda()\n",
    "#optimizer =\n",
    "history_SGDMN = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)\n",
    "history_SGDMN.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(model, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Complétez cette cellule pour entraîner avec Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNet()\n",
    "model.cuda()\n",
    "#optimizer =\n",
    "history_adam = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)\n",
    "history_adam.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(model, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Quelle méthode semble être la meilleure dans ce cas-ci?\n",
    "- Remarquez-vous une différence d'overfitting?\n",
    "- Dans une nouvelle cellule, changez le taux d'apprentissage de Adam pour 0.001. Que remarquez-vous maintenant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la réponse à la question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNet()\n",
    "model.cuda()\n",
    "#optimizer =\n",
    "history_adam = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)\n",
    "history_adam.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(model, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2: Horaire d'entraînement\n",
    "\n",
    "Une pratique courante utilisée en apprentissage profond est de faire diminuer le taux d'apprentissage pendant l'entraînement.\n",
    "\n",
    "Pour ce faire, PyTorch fournit plusieurs fonctions (ExponentialLR, LambdaLR, MultiStepLR, etc.).  Dans ce notebook, on utilisera les [callbacks correspondant de Poutyne](https://poutyne.org/callbacks.html#lr-schedulers) qui cachent sous le capot les fonctions de PyTorch.\n",
    "\n",
    "Voici un exemple avec ExponentialLR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "batch_size = 128\n",
    "lr = 0.01\n",
    "n_epoch = 10\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "gamma = 0.8\n",
    "scheduler = pt.ExponentialLR(gamma)\n",
    "\n",
    "history = train(model, optimizer, cifar_train, n_epoch, batch_size, callbacks=[scheduler], use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons la valeur du taux d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.display(display_lr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice\n",
    "\n",
    "- Utilisez [MultiStepLR](http://pytorch.org/docs/master/optim.html#torch.optim.lr_scheduler.MultiStepLR) pour modifier le taux d'apprentissage pour un epoch précis.\n",
    "\n",
    "1. Commencez avec un taux d'apprentissage trop élevé pour que le réseau puisse apprendre quelque chose.\n",
    "2. Diminuez-le progressivement jusqu'à ce que le réseau apprenne.\n",
    "3. Trouvez le moment où la validation semble avoir atteint un plateau.\n",
    "4. Diminuez le taux par 2 à ce moment et réentraîner le réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "epoch_list = [] # TODO liste à remplir au fur et à mesure que les points 3 et 4 sont itérés.\n",
    "\n",
    "batch_size = 128\n",
    "lr = 10\n",
    "n_epoch = 20\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = pt.MultiStepLR(milestones=epoch_list, gamma=0.5)\n",
    "\n",
    "history = train(model, optimizer, cifar_train, n_epoch, batch_size, callbacks=[scheduler], use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history.display(display_lr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Voyez-vous une différence en diminuant le taux d'apprentissage par 2 après x epochs?\n",
    "- Pourquoi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour aller plus loin sur les horaires d'entraînement\n",
    "\n",
    "On vient de faire \"à la main\" ce que la classe [ReduceLROnPlateau](https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.ReduceLROnPlateau) de PyTorch nous permet de faire automatiquement. Essentiellement, cette classe nous permet de monitorer une métrique et de réduire le taux d'apprentissage lorsque cette métrique stagne pour un certain nombre d'epochs. Ce nombre d'epoch est appelé la \"patience\". Nous allons utiliser le callback [poutyne.ReduceLROnPlateau](https://poutyne.org/callbacks.html#poutyne.ReduceLROnPlateau) de Poutyne qui prend en paramètre le nom de la métrique à monitorer en plus des autres arguments de la classe de PyTorch.\n",
    "\n",
    "Notez bien la description du paramètre `patience` dans la documentation de PyTorch:\n",
    "> **patience** - Number of epochs with no improvement after which learning rate will be reduced. For example, if patience = 2, then we will ignore the first 2 epochs with no improvement, and will only decrease the LR after the 3rd epoch if the loss still hasn’t improved then.\n",
    "\n",
    "Dans la cellule ci-dessous, on monitore l'exactitude en validation avec une patience de 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "batch_size = 128\n",
    "lr = 0.5\n",
    "n_epoch = 20\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = pt.ReduceLROnPlateau(monitor='val_acc', mode='max', patience=1, factor=0.5)\n",
    "\n",
    "history = train(model, optimizer, cifar_train, n_epoch, batch_size, callbacks=[scheduler], use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.display(display_lr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3: Batch Normalization\n",
    "\n",
    "Voici l'architecture du réseau de neurones convolutionnels que vous avez utilisé jusqu'à présent pour faire de la classification sur Cifar10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CifarNetBatchNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(10, 50, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(50, 150, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(150 * 8 * 8, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.flatten(1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice\n",
    "\n",
    "- Modifier l'architecture du réseau en ajoutant de la batch normalization entre les couches de convolutions et les ReLUs (essentiellement, on devait avoir `Conv2d -> BatchNorm2d -> ReLU`) et entraîner le nouveau réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNetBatchNorm()\n",
    "model.cuda()\n",
    "\n",
    "lr = 0.01\n",
    "batch_size = 128\n",
    "n_epoch = 5\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "history = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)\n",
    "history.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "- Comparer l'entraînement du réseau avec et sans la batch normalization (Section 1.2 avec SGD, où on a entraîné le réseau sans batch normalization avec le même taux d'apprentissage). Que remarquez-vous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effet de la batch normalization sur le taux d'apprentissage\n",
    "\n",
    "Commençons par entraîner un réseau avec un taux d'apprentissage élevé. Vous pouvez augmenter le nombre d'epochs si vous voulez voir une plus grande différence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5\n",
    "batch_size = 1024\n",
    "n_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CifarNet()\n",
    "model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "history = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons maintenant d'entraîner le réseau utilisant la batch normalization avec les mêmes hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CifarNetBatchNorm()\n",
    "model.cuda()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "history = train(model, optimizer, cifar_train, n_epoch, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Que pouvez-vous conclure sur l'effet de la batch normalization sur le taux d'apprentissage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse\n",
    "\n",
    "Après l'entraînement, il est important d'analyser les résultats obtenus.\n",
    "Commençons par tester le réseau en utilisant la fonction `validate_ranking`.\n",
    "Cette fonction sépare les résultats bien classés des erreurs et retourne pour chaque image, un score (qu'on peut voir comme une probabilité), la vraie classe et la classe prédite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good, errors = validate_ranking(model, cifar_test, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, regardons quelques exemples d'images bien classés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random(good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et quelques exemples mal classés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est aussi possible de regarder les exemples où le réseau est le plus confiant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_best(good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou l'inverse, ceux qui ont obtenus les moins bons scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_worst(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, il peut être intéressant de regarder les exemples les plus difficiles.\n",
    "Soit ceux qui ont été bien classés, mais qui ont eu un mauvais score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_worst(good)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou ceux qui ont été mal classés, mais qui ont quand même réussi à obtenir un bon score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_best(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions \n",
    "- En observant les résultats obtenus, que pouvez-vous dire sur les performances du réseau?\n",
    "- Quelle classe semble être facile? Pourquoi?\n",
    "- Quelle classe semble être difficile? Pourquoi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 4: Initialisation des poids\n",
    "\n",
    "Dans cette section, vous testerez différentes techniques d'initialisations et observerez leurs effets sur le gradient et l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train, cifar_test = load_cifar10()\n",
    "cifar_train.transform = ToTensor()\n",
    "cifar_test.transform = ToTensor()\n",
    "\n",
    "train_loader, valid_loader = train_valid_loaders(cifar_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée ici un réseau de neurones assez simple composé de 5 couches cachées (6 couches au total) et avec un choix pour la fonction d'activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = dict(\n",
    "    tanh=nn.Tanh,\n",
    "    relu=nn.ReLU\n",
    ")\n",
    "\n",
    "def create_fully_connected_network(activation):\n",
    "    assert activation in activations\n",
    "    activation = activations[activation]\n",
    "    num_neurons = 1000\n",
    "    return nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(32*32*3, num_neurons),\n",
    "        activation(),\n",
    "        nn.Linear(num_neurons, num_neurons),\n",
    "        activation(),\n",
    "        nn.Linear(num_neurons, num_neurons),\n",
    "        activation(),\n",
    "        nn.Linear(num_neurons, num_neurons),\n",
    "        activation(),\n",
    "        nn.Linear(num_neurons, num_neurons),\n",
    "        activation(),\n",
    "        nn.Linear(num_neurons, 10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va jouer avec différentes fonctions d'initialisation. Créons donc une fonction nous permettant d'initialiser tous les poids de notre réseau de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(network, initialization_function):\n",
    "    for module in network.modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            initialization_function(module.weight)\n",
    "            init.zeros_(module.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'intéresse aux gradients qui circulent dans le réseau de neurones lors de la rétropropagation de manière générale.\n",
    "Ceci est à distinguer du gradient calculé pour chacun des poids individuels du réseau de neurones.\n",
    "Le gradient circulant pendant la rétropropagation nous donne une idée de la possibilité de changements des poids de la couche en question. \n",
    "Étant donné que le gradient est le même lors de l'addition, on peut se servir du biais pour mesurer le gradient circulant dans le réseau.\n",
    "Les fonctions suivantes procèdent donc de la façon suivante:\n",
    "- On parcourt le jeu de données d'entraînement en batch;\n",
    "- Pour chacune des batchs, on garde pour chacune des couches le gradient des biais de la couche;\n",
    "- Une fois que toutes les batchs ont été traitées, on calcule un histogramme des gradients pour chaque couche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def save_gradient(sequential_network, output_dictionary):\n",
    "    layer_number = 1\n",
    "    for layer in sequential_network:\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            # On ignore la dernière couche qui est la couche de \n",
    "            # classification.\n",
    "            if layer_number == 6:\n",
    "                continue\n",
    "\n",
    "            with torch.no_grad():\n",
    "                grad = layer.bias.grad.flatten().cpu().numpy()\n",
    "            grad = grad[grad != 0]\n",
    "            output_dictionary[layer_number].append(grad)\n",
    "            layer_number += 1\n",
    "\n",
    "def plot_gradients_per_layer(gradients_per_layer):\n",
    "    for layer_number, grads in gradients_per_layer.items():\n",
    "        grad = np.concatenate(grads)\n",
    "        hist, bin_edges = np.histogram(grad, bins=100)\n",
    "        hist = hist / hist.sum() * 100\n",
    "\n",
    "        plt.plot(bin_edges[:-1], hist, label=f'Layer {layer_number}')\n",
    "\n",
    "def plot_gradient(network):\n",
    "    gradients_per_layer = defaultdict(list)\n",
    "    network.cuda()\n",
    "    for x, y in train_loader:\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        \n",
    "        output = network(x)\n",
    "        loss = F.cross_entropy(output, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        save_gradient(network, gradients_per_layer)\n",
    "\n",
    "        network.zero_grad(True)\n",
    "\n",
    "    plot_gradients_per_layer(gradients_per_layer)\n",
    "    plt.title('Gradient histogram')\n",
    "    plt.xlabel('Gradient value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction ci-dessous est la fonction qui est utilisée comme référence dans [l'article introduisant l'initialisation Glorot/Xavier](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf) et est d'ailleurs celle utilisé par PyTorch par défaut dans les couches linéaires. Nous allons l'utiliser pour la comparer avec l'initialisation de Glorot/Xavier et celle de Kaiming He."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_uniform(weight):\n",
    "    bound = 1. / np.sqrt(weight.shape[1])\n",
    "    init.uniform_(weight, -bound, bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Réseau avec activation tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction tanh était la fonction d'activation la plus utilisée avant l'arrivée de la fonction ReLU. Plusieurs fonctions d'initialisation ont donc été conçues avec cette fonction d'activation en tête. Investiguons donc l'effet des différentes fonctions d'initialisation sur un réseau avec des activations tanh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tanh_network = create_fully_connected_network('tanh')\n",
    "tanh_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons l'histogramme des gradients lorsqu'on utilise l'initialisation standard (de référence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_network(tanh_network, standard_uniform)\n",
    "\n",
    "plot_gradient(tanh_network)\n",
    "plt.title('Standard uniform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons l'histogramme des gradients lorsqu'on utilise l'initialisation de Glorot/Xavier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_network(tanh_network, init.xavier_uniform_)\n",
    "\n",
    "plot_gradient(tanh_network)\n",
    "plt.title('Xavier uniform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons l'histogramme des gradients lorsqu'on utilise l'initialisation de Kaiming He."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_network(tanh_network, init.kaiming_uniform_)\n",
    "\n",
    "plot_gradient(tanh_network)\n",
    "plt.title('Kaiming uniform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- À partir des graphiques pour chacune des fonctions d'initialisation, que peut-on dire sur la différence d'initialisation entre les différents types d'initialisation?\n",
    "- Intuitivement, pourquoi serait-il préférable d'avoir une variance similaire pour le gradient circulant dans chacune des couches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que l'on a observé l'effet de l'initialisation sur le gradient circulant dans le réseau, regardons si l'effet est répercuté sur l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînons le réseau avec l'initialisation standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_network(tanh_network, standard_uniform)\n",
    "\n",
    "history = train(tanh_network, 'sgd', cifar_train, epochs, batch_size)\n",
    "history.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(tanh_network, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons maintenant l'histogramme des gradients du réseau entraîné avec l'initialisation standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient(tanh_network)\n",
    "plt.title('Trained tanh network with standard uniform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Quelle différence remarquez-vous par rapport à l'histogramme du gradient circulant de l'initialisation standard avant l'entraînement (Voir le graphique \"Standard uniform\" plus haut) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînons le réseau avec l'initialisation Xavier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_network(tanh_network, init.xavier_uniform_)\n",
    "\n",
    "history = train(tanh_network, 'sgd', cifar_train, epochs, batch_size)\n",
    "history.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(tanh_network, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons maintenant l'histogramme des gradients du réseau entraîné avec l'initialisation Xavier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient(tanh_network)\n",
    "plt.title('Trained tanh network with Xavier uniform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînons le réseau avec l'initialisation Kaiming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "initialize_network(tanh_network, init.kaiming_uniform_)\n",
    "\n",
    "history = train(tanh_network, 'sgd', cifar_train, epochs, batch_size)\n",
    "history.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(tanh_network, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons maintenant l'histogramme des gradients du réseau entraîné avec l'initialisation Kaiming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient(tanh_network)\n",
    "plt.title('Trained tanh network with Kaiming uniform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Que notez-vous en termes de performances des différentes techniques d'initialisation ?\n",
    "- Comparez les graphiques pour les initialisations Xavier et Kaiming avant et après entraînement. Que remarquez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Réseau avec activation ReLU\n",
    "\n",
    "Effectuons donc le même processus mais c'est fois-ci avec la fonction ReLU. \n",
    "\n",
    ">Notons que la fonction calculant les histogrammes enlève tous les gradients qui sont exactement à zéro. Autrement, chaque histogramme aurait un grand pic à zéro nous empêchant de voir la distribution du reste des gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_network = create_fully_connected_network('relu')\n",
    "relu_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_network(relu_network, standard_uniform)\n",
    "\n",
    "plot_gradient(relu_network)\n",
    "plt.title('Standard uniform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_network(relu_network, init.xavier_uniform_)\n",
    "\n",
    "plot_gradient(relu_network)\n",
    "plt.title('Xavier uniform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_network(relu_network, init.kaiming_uniform_)\n",
    "\n",
    "plot_gradient(relu_network)\n",
    "plt.title('Kaiming uniform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effectuons les entraînements avec les différentes fonctions d'initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "initialize_network(relu_network, standard_uniform)\n",
    "\n",
    "history = train(relu_network, 'sgd', cifar_train, epochs, batch_size)\n",
    "history.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(relu_network, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient(relu_network)\n",
    "plt.title('Trained ReLU network with standard uniform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_network(relu_network, init.xavier_uniform_)\n",
    "\n",
    "history = train(relu_network, 'sgd', cifar_train, epochs, batch_size)\n",
    "history.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(relu_network, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient(relu_network)\n",
    "plt.title('Trained ReLU network with Xavier uniform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_network(relu_network, init.kaiming_uniform_)\n",
    "\n",
    "history = train(relu_network, 'sgd', cifar_train, epochs, batch_size)\n",
    "history.display()\n",
    "print('Exactitude en test: {:.2f}'.format(test(relu_network, cifar_test, batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradient(relu_network)\n",
    "plt.title('Trained ReLU network with Kaiming uniform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "- Quelles similarités remarquez-vous en termes de performance et de gradient entre le réseau avec activation tanh et le réseau avec activation ReLU ?\n",
    "- Quelles différences remarquez-vous en termes de performance et de gradient entre le réseau avec activation tanh et le réseau avec activation ReLU ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
