{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes sur le laboratoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation de commandes\n",
    "\n",
    "Dans ce laboratoire, il est parfois intéressant (mais pas nécessaire à strictement parler) d'entrer certaines commandes dans le terminal (ou ligne de commande). Dans l'explorateur de fichiers de Jupyter Notebook, il est très simple d'ouvrir un terminal via le menu New (ou Nouveau):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par contre, il n'est malheureusement pas possible d'obtenir un terminal si Google Colab est utilisé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation de Google Colab\n",
    "\n",
    "Si vous utilisez Google Colab, suivez les instructions ci-dessous.\n",
    "\n",
    "Tout d'abord, sélectionnez l'option GPU de Colab avec *Edit > Notebook settings* et sélectionner GPU comme Hardware accelerator. Installer ensuite deeplib avec la commande suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ulaval-damas/glo4030-labs.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 1: Introduction à PyTorch\n",
    "\n",
    "Le but de ce laboratoire est de se familiariser avec PyTorch en l'utilisant pour faire de la classification sur deux jeux de données connus: MNIST et CIFAR-10. On aura donc une vue d'ensemble de l'utilisation de PyTorch. Prenez donc le temps de lire le code et d'essayer de comprendre en haut niveau ce qui se passe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule ci-dessous importe les différents modules qui sont utilisés dans ce notebook. Notamment, en plus de différents modules de PyTorch (torch.\\*), on importe deeplib qui est une libraire écrite spécialement pour les notebook de ce cours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "from deeplib.datasets import load_mnist, load_cifar10, train_valid_loaders\n",
    "from sklearn.metrics import accuracy_score\n",
    "from deeplib.net import MnistNet, CifarNet\n",
    "from deeplib.history import History\n",
    "from deeplib.visualization import plot_images\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "\n",
    "MNIST est un jeu de données contenant des images de chiffres manuscrits.\n",
    "\n",
    "Le jeu de données est séparé comme suit: 50 000 images sont utilisées en entraînement et 10 000 en test.\n",
    "\n",
    "Pour obtenir les objets [`Dataset`](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) de PyTorch pour les exemples d'entraînement et de test, on utilise la fonction `load_mnist` dans deeplib qui utilise la librairie [`torchvision`](https://pytorch.org/vision/main/) sous le capot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist, mnist_test = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation du jeu de données\n",
    "\n",
    "Exécuter cette cellule plusieurs fois pour visualiser différents exemples du jeu de données.\n",
    "\n",
    "La fonction `plot_images` est une fonction venant de deeplib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = random.sample([x for x in range(len(mnist))], 9)\n",
    "images = [np.array(mnist[i][0]) for i in idx]\n",
    "targets = [mnist[i][1] for i in idx]\n",
    "\n",
    "plot_images(images, targets, gray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut indexer les datasets de PyTorch comme une liste. Généralement, chaque élément d'un dataset va être un tuple `(x, y)`. Le terme `x` va correspondre à notre exemple. Le terme `y` va correspondre à notre étiquette (ou label, target) sous forme d'index (par exemple, on pourrait avoir 0 pour chien et 1 pour chat si on cherchait à différencier des images de chats et de chien). Avec MNIST, `x` sera les pixels de l'image et `y` sera le chiffre à classifier.\n",
    "\n",
    "Les cellules ci-dessous affichent le premier élément `(x, y)` du jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = mnist[0]\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche l'image `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche l'étiquette `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les datasets de torchvision ont un attribut permettant d'effectuer une transformation sur nos images. Dans notre cas, on veut simplement obtenir un tenseur pour PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.transform = ToTensor()\n",
    "mnist_test.transform = ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'entraînement, on a besoin d'une fonction ``train`` pour entraîner le réseau, d'une fonction ``validate`` pour estimer la performance de notre modèle au fur et à mesure de l'optimisation et d'une fonction ``test`` pour estimer la performance de notre modèle sur des données jamais observées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque epoch, la fonction ``train`` passe au travers de toutes les images du jeu de données dans un ordre aléatoire et met à jour les poids du réseau selon la perte calculée.<br>\n",
    "Pour entraîner le réseau, la fonction doit recevoir 3 hyperparamètres: \n",
    "1. le nombre d'epochs qui indique combien de fois toutes les images du jeu de données seront observées; \n",
    "2. la taille de la batch qui indique combien d'images seront traitées à la fois;\n",
    "3. le taux d'apprentissage qui détermine la vitesse à laquelle chaque poids du réseau sera modifié.\n",
    "\n",
    "Pendant l'entraînement, une partie des données est utilisée pour créer un ensemble de validation qui permet d'estimer les performances de généralisation du modèle.\n",
    "\n",
    "Finalement, on sauvegarde aussi quelques informations importantes afin de visualiser ce qui se passe pendant l'entraînement.\n",
    "\n",
    "Le code est commenté pour donner plus de détails du déroulement de l'entraînement et des subtilités de PyTorch. Vous aurez l'occasion dans les prochains laboratoires de mieux comprendre tous ces détails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, n_epoch, batch_size, learning_rate, use_gpu=False):\n",
    "    \"\"\"\n",
    "    Entraîne un réseau de neurones de classification pour un certain nombre d'epochs \n",
    "    avec PyTorch.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Un réseau de neurones instancié avec PyTorch.\n",
    "        dataset (Dataset): Un jeu de données PyTorch.\n",
    "        n_epoch (int): Le nombre d'epochs.\n",
    "        batch_size (int): La taille des batchs.\n",
    "        learning_rate (float): Le taux d'apprentissage pour SGD.\n",
    "        use_gpu (bool): Si les données doivent être envoyées sur GPU.\n",
    "    \n",
    "    Returns:\n",
    "        Retourne un objet History permettant de faire des graphiques\n",
    "        de l'évolution de l'entraînement.\n",
    "    \"\"\"\n",
    "    # La classe History vient de deeplib. Elle va nous permettre de faire les graphiques\n",
    "    # donnant l'évolution de la perte et de l'exactitude (accuracy).\n",
    "    history = History()\n",
    "    \n",
    "    # La fonction de perte que nous utilisons ici est l'entropy croisée\n",
    "    # L'optimiseur que nous utilisons ici est le classique SGD.\n",
    "    # Des liens vers la documentation de PyTorch sont en commentaires.\n",
    "    criterion = nn.CrossEntropyLoss()  # https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # https://pytorch.org/docs/stable/optim.html#torch.optim.SGD\n",
    "    \n",
    "    # La fonction train_valid_loaders vient de deeplib. Elle nous retourne deux DataLoaders:\n",
    "    # un pour l'ensemble d'entraînement et un pour l'ensemble de test. Essentiellement,\n",
    "    # DataLoader est une classe de PyTorch nous permettant de faire des batchs avec la taille\n",
    "    # désirée. La fonction train_valid_loaders effectue la répartition aléatoire des exemples\n",
    "    # en entraînement et en validation.\n",
    "    train_loader, valid_loader = train_valid_loaders(dataset, batch_size=batch_size)\n",
    "\n",
    "    # C'est ici que la boucle d'entraînement commence. On va donc faire n_epochs epochs.\n",
    "    for i in range(n_epoch):\n",
    "        # Les réseaux de neurones avec PyTorch ont un méthode train() en plus d'une méthode \n",
    "        # eval(). Ces deux méthodes indiquent au réseau s'il est en entraînement ou bien en test.\n",
    "        # Ceci permet au réseau de modifier son comportement en fonction. On va le voir plus tard\n",
    "        # certaines couches agissent différemment selon le mode, nommément le dropout et la \n",
    "        # batch normalization.\n",
    "        model.train()\n",
    "        \n",
    "        # La prochaine ligne active simplement le calcul du gradient. Le gradient est ce qui va\n",
    "        # nous permettre de mettre à jour les poids du réseau de neurones. En test, le calcul du\n",
    "        # gradient sera désactivé étant qu'il n'est pas nécessaire et qu'il peut engendrer des \n",
    "        # fuites de mémoire si la rétro-propagation n'est pas effectuée.\n",
    "        with torch.enable_grad():\n",
    "            # À chaque epoch, on parcourt l'ensemble d'entraînement au complet via le DataLoader\n",
    "            # qui nous le retourne en batch (x, y) comme mentionné plus haut. La variable inputs \n",
    "            # correspond donc à une batch d'exemples (x) et targets correspond à une batch \n",
    "            # d'étiquettes (y).\n",
    "            for inputs, targets in train_loader:\n",
    "                # On envoie les exemples et leurs étiquettes sur GPU via la méthode cuda() si \n",
    "                # demandé.\n",
    "                if use_gpu:\n",
    "                    inputs = inputs.cuda()\n",
    "                    targets = targets.cuda()\n",
    "\n",
    "                # La méthode zero_grad() de l'optimiseur permet de mettre la valeur du gradient\n",
    "                # à zéro de façon à effacer le gradient calculé auparavant. Si ceci n'était pas \n",
    "                # fait, le nouveau gradient serait additionné à l'ancien gradient ce qui poserait\n",
    "                # problème.\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # C'est ici que finalement le réseau de neurones est appelé. On lui donne en entrée\n",
    "                # un exemple et en sortie il nous donne ses prédictions (ici, des scores de \n",
    "                # classification).\n",
    "                output = model(inputs)\n",
    "\n",
    "                # Une fois nos prédictions obtenues, on calcule la perte avec la fonction de perte \n",
    "                # qui nous retourne un tenseur scalaire. \n",
    "                loss = criterion(output, targets)\n",
    "                # Ce tenseur scalaire nous permet de calculer le gradient. C'est ce que la méthode\n",
    "                # backward() vient faire pour nous via la rétropropagation.\n",
    "                loss.backward()\n",
    "                # Une fois que le gradient est calculé, il ne reste que mettre à jour les poids du\n",
    "                # réseau de neurones. C'est ce que la méthode step() de l'optimiseur vient faire\n",
    "                # pour nous.\n",
    "                optimizer.step()\n",
    "\n",
    "        # Après chaque epoch d'entraînement, on va venir calculer la perte et l'exactitude \n",
    "        # (accuracy) sur l'ensemble d'entraînement et de validation.\n",
    "        train_acc, train_loss = validate(model, train_loader, use_gpu)\n",
    "        val_acc, val_loss = validate(model, valid_loader, use_gpu)\n",
    "        history.save(dict(acc=train_acc, val_acc=val_acc, loss=train_loss, val_loss=val_loss, lr=learning_rate))\n",
    "        print(f'Epoch {i} - Train acc: {train_acc:.2f} - Val acc: {val_acc:.2f} - Train loss: {train_loss:.4f} - Val loss: {val_loss:.4f}')\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque image du jeu de donnée, la fonction ``validate`` fait prédire une classe au réseau entraîné et compare le résultat avec la vraie réponse. Elle retourne le pourcentage de réponse correcte (c'est-à-dire l'exactitude, ou *accuracy* en anglais) ainsi que la perte moyenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_loader, use_gpu=False):\n",
    "    \"\"\"\n",
    "    Test un réseau de neurones de classification pour un certain nombre d'epochs \n",
    "    avec PyTorch.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Un réseau de neurones instancié avec PyTorch.\n",
    "        valid_loader (DataLoader): Un DataLoader PyTorch tel qu'instancié dans train() \n",
    "            et test().\n",
    "        use_gpu (bool): Si les données doivent être envoyées sur GPU.\n",
    "            \n",
    "    Returns:\n",
    "        Retourne un tuple (exactitude, perte) pour les données du DataLoader en argument.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Les étapes de la fonction validate est très similaire à celle de la fonction train.\n",
    "    # Essentiellement, le réseau est mis en mode évaluation au lieu d'entraînement et le \n",
    "    # calcul du gradient est désactivé. Il n'y a bien sûr pas d'utilisation d'un optimiseur.\n",
    "    true = []\n",
    "    pred = []\n",
    "    val_loss = []\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in valid_loader:\n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "\n",
    "            output = model(inputs)\n",
    "\n",
    "            predictions = output.max(dim=1)[1]\n",
    "\n",
    "            val_loss.append(criterion(output, targets).item())\n",
    "            true += targets.cpu().numpy().tolist()\n",
    "            pred += predictions.cpu().numpy().tolist()\n",
    "\n",
    "    return accuracy_score(true, pred) * 100, sum(val_loss) / len(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `test` est utilisée à la fin de l'entraînement sur l'ensemble de test et affiche le pourcentage de réponse correcte ainsi que la perte moyenne sur cet ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset, batch_size, use_gpu=False):\n",
    "    \"\"\"\n",
    "    Test un réseau de neurones de classification pour un certain nombre d'epochs \n",
    "    avec PyTorch. La fonction affiche l'exactitude et la perte moyenne.\n",
    "    \n",
    "    Args:\n",
    "        model (nn.Module): Un réseau de neurones instancié avec PyTorch.\n",
    "        dataset (Dataset): Un jeu de données PyTorch.\n",
    "        batch_size (int): La taille des batchs.\n",
    "        use_gpu (bool): Si les données doivent être envoyées sur GPU.\n",
    "    \"\"\"\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "    test_acc, test_loss = validate(model, test_loader, use_gpu=use_gpu)\n",
    "    print('Test acc: {:.2f} - Test loss: {:.4f}'.format(test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînons un modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistNet()\n",
    "model.cuda()\n",
    "\n",
    "n_epoch = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "\n",
    "history = train(model, mnist, n_epoch, batch_size, learning_rate, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la méthode `display` de la classe `History`, on peut visualiser l'entraînement précédent.\n",
    "\n",
    "Le premier graphique montre l'évolution de l'exactitude (accuracy) du modèle sur le jeu de données d'entraînement et sur celui de validation. Le deuxième montre la perte sur les deux jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, évaluons les performances du modèle sur le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, mnist_test, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Différences CPU - GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour faire exécuter le code sur GPU, il faut déplacer le model, les inputs et les targets sur le GPU. \n",
    "\n",
    "Le réseau contient deux couches de convolutions qui servent à extraire des caractéristiques des images tandis que les couches linéaires servent de classifieur. Il s'agit d'un pipeline commun pour toutes les classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gpu = MnistNet()\n",
    "model_gpu.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparons le temps d'exécution sur CPU et sur GPU. Pour ce faire, entraînons le réseau pour 5 epochs sur CPU et 5 epochs sur GPU et comparons les temps de traitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "batch_size = 256\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pendant l'entraînement, vérifier l'utilisation du CPU avec la commande ``top`` (ou ``htop``). Voir la section \"Utilisation de commandes\" tout en haut du notebook pour l'utilisation de commande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training on CPU')\n",
    "model = MnistNet()\n",
    "\n",
    "start_cpu = time.time()\n",
    "history = train(model, mnist, epoch, batch_size, lr)\n",
    "end_cpu = time.time()\n",
    "\n",
    "cpu_time = end_cpu - start_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour vous assurer que le réseau entraîne bien sur GPU, utiliser la commande \n",
    "\n",
    "``watch -n 1 nvidia-smi`` \n",
    "\n",
    "Observer l'utilisation de la carte et la quantité de mémoire utilisée pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training on GPU')\n",
    "model_gpu = MnistNet()\n",
    "model_gpu.cuda()\n",
    "\n",
    "start_gpu = time.time()\n",
    "history_gpu = train(model_gpu, mnist, epoch, batch_size, lr, use_gpu=True)\n",
    "end_gpu = time.time()\n",
    "\n",
    "gpu_time = end_gpu - start_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CPU - Training time: {:.2f}s'.format(cpu_time))\n",
    "print('GPU - Training time: {:.2f}s'.format(gpu_time))\n",
    "print('Ratio: {:.2f}x'.format((cpu_time) / (gpu_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10\n",
    "\n",
    "CIFAR-10 est un jeu de données comportant des images séparés en 10 classes:<br>\n",
    "0 - Avion<br>\n",
    "1 - Voiture<br>\n",
    "2 - Oiseau<br>\n",
    "3 - Chat<br>\n",
    "4 - Chevreuil<br>\n",
    "5 - Chien<br>\n",
    "6 - Grenouille<br>\n",
    "7 - Cheval<br>\n",
    "8 - Bateau<br>\n",
    "9 - Camion<br>\n",
    "\n",
    "Le jeu de données contient 50000 images d'entraînement. On en utilisera 40000 pour l'entraînement et 10000 pour la validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar, cifar_test = load_cifar10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois, vous pouvez exécuter cette cellule plusieurs fois pour bien visualiser le jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'\n",
    "]\n",
    "\n",
    "idx = random.sample([x for x in range(len(cifar))], 9)\n",
    "images = [np.array(cifar[i][0]) for i in idx]\n",
    "images = np.asarray(images)\n",
    "targets = [cifar[i][1] for i in idx]\n",
    "\n",
    "plot_images(images, targets, label_names=label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois, on désire obtenir des tensors de notre dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar.transform = ToTensor()\n",
    "cifar_test.transform = ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercices\n",
    "\n",
    "- Pour répondre aux questions suivantes, vous avez le contenu de ces 3 cellules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "\n",
    "model = CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "history = train(model, cifar, epoch, batch_size, learning_rate, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, cifar_test, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effet du nombre d'epochs\n",
    "\n",
    "#### Exercice\n",
    "\n",
    "- Modifiez le nombre d'epochs et observez les performances du réseau.\n",
    "\n",
    "#### Questions\n",
    "\n",
    "- Que se passe-t-il s'il est trop petit?\n",
    "- Que se passe-t-il s'il est trop grand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# epoch = ...\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "\n",
    "model = CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "history = train(model, cifar, epoch, batch_size, learning_rate, use_gpu=True)\n",
    "history.display()\n",
    "test(model, cifar_test, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effet de la taille de la batch\n",
    "\n",
    "#### Exercice\n",
    "\n",
    "- Modifiez la taille de la batch et observez l'utilisation de la carte graphique. \n",
    "\n",
    "#### Questions\n",
    "\n",
    "- Sur quoi est-ce que la taille de la batch semble avoir le plus d'impact? \n",
    "\n",
    "    **Note**: Pour pouvoir observer les changements au niveau de l'utilisation de la mémoire du GPU, il est préférable de redémarrer le kernel du notebook entre chaque tentative (dans le menu Kernel). Si vous prenez ce chemin, n'oubliez pas d'exécuter les cellules nécessaires plus haut dans le notebook (les imports, les fonctions train, validate, etc.).\n",
    "    \n",
    "- Est-ce qu'elle impacte les performances?\n",
    "- Que peut-on conclure sur la taille de batch optimale?\n",
    "\n",
    "     **Note**: on ne demande pas de trouver cette taille optimale mais de commenter sur la manière dont on la trouverait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "# batch_size = ...\n",
    "learning_rate = 0.1\n",
    "\n",
    "model = CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "history = train(model, cifar, epoch, batch_size, learning_rate, use_gpu=True)\n",
    "history.display()\n",
    "test(model, cifar_test, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "# batch_size = ...\n",
    "learning_rate = 0.1\n",
    "\n",
    "model = CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "history = train(model, cifar, epoch, batch_size, learning_rate, use_gpu=True)\n",
    "history.display()\n",
    "test(model, cifar_test, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effet du taux d'apprentissage (lr)\n",
    "\n",
    "Finalement, observez l'impact du taux d'apprentissage sur l'entraînement.\n",
    "\n",
    "#### Questions\n",
    "\n",
    "- Que se passe-t-il s'il est trop grand?\n",
    "- S'il est trop petit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "batch_size = 64\n",
    "# learning_rate = ...\n",
    "\n",
    "model = CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "history = train(model, cifar, epoch, batch_size, learning_rate, use_gpu=True)\n",
    "history.display()\n",
    "test(model, cifar_test, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "batch_size = 64\n",
    "# learning_rate = ...\n",
    "\n",
    "model = CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "history = train(model, cifar, epoch, batch_size, learning_rate, use_gpu=True)\n",
    "history.display()\n",
    "test(model, cifar_test, batch_size, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Défi\n",
    "\n",
    "- Modifiez les hyperparamètres pour améliorer les performances du réseau.<br>\n",
    "Essayez d'obtenir plus de 65% en test.\n",
    "\n",
    "- Vous pouvez aussi tenter de battre l'état de l'art: http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation d'une librairie pour l'entraînement\n",
    "\n",
    "Comme vous l'avez peut-être remarqué, les fonctions `train` et `test` que nous avons utilisées sont bien pratiques. Il existe différentes librairies nous permettant de ne pas devoir définir ces fonctions pour chacun de nos projets. Lorsqu'approprié, nous utiliserons une de ces librairies dans les laboratoires de ce cours. Nous avons choisi d'utiliser la librairie [Poutyne](https://poutyne.org/) qui est développée ici même à l'Université Laval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons nos hyperparamètres usuels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poutyne peut prendre en entrée des Numpy arrays ou des tenseurs via sa méthode `fit` ou bien des objets qui sont itérables comme des `DataLoader` de PyTorch via sa méthode `fit_generator`. Définissons donc des `DataLoader` comme le font les fonctions `train` et `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = train_valid_loaders(cifar, batch_size=batch_size)\n",
    "test_loader = DataLoader(cifar_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importons Poutyne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import poutyne as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procédons maintenant à l'entraînement. La principale classe de Poutyne est la classe [`Model`](https://poutyne.org/model.html) qui nous servira à effectuer l'entraînement. Également, n'hésitez pas à jeter un coup d'oeil à la classe [`Experiment`](https://poutyne.org/experiment.html) qui permet de sauvegarder automatiquement un tas d'information comme des points de sauvegarde (checkpoints) et des logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On instance notre réseau ainsi que l'optimiseur comme à l'habitude.\n",
    "net = CifarNet()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# On crée un objet Model de Poutyne avec la fonction de perte et les métriques souhaitées.\n",
    "model = pt.Model(net, optimizer, 'cross_entropy', batch_metrics=['accuracy'])\n",
    "model.cuda()\n",
    "\n",
    "# Comme dit précedemment, on utilise la méthode `fit_generator` pour procéder à l'entraînement.\n",
    "history = model.fit_generator(train_loader, valid_loader, epochs=epoch)\n",
    "\n",
    "# La classe History peut aussi prendre un historique de Poutyne en entrée.\n",
    "History(history).display()\n",
    "\n",
    "# Finalement, on utilise la fonction evaluate_generator pour calculer la perte et l'exactitude sur\n",
    "# notre ensemble de test.\n",
    "test_loss, test_acc = model.evaluate_generator(test_loader)\n",
    "print('test_loss: {:.4f} test_acc: {:.2f}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pour aller plus loin\n",
    "\n",
    "Un aspect intéressant de Poutyne est l'utilisation de [callbacks](https://poutyne.org/callbacks.html) qui permettent d'effectuer des actions pendant l'entraînement. Dans l'exemple suivant, on utilise deux types de callbacks: un permettant de faire des points de sauvegarde et l'autre permettant de logger dans un CSV les statistiques d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CifarNet()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "callbacks = [\n",
    "    # Effectue des points de sauvegarde après chaque epoch dans le fichier last_epoch.ckpt.\n",
    "    pt.ModelCheckpoint('logs/last_epoch.ckpt', temporary_filename='last_epoch.ckpt.tmp'),\n",
    "\n",
    "    # Effectue des points de sauvegarde à chaque fois qu'il y a amélioration de l'exactitude\n",
    "    # en validation. Le nom du fichier va contenir le numéro de l'epoch correspondante.\n",
    "    pt.ModelCheckpoint('logs/best_epoch_{epoch}.ckpt', monitor='val_acc', mode='max', save_best_only=True, restore_best=True, verbose=True, temporary_filename='best_epoch.ckpt.tmp'),\n",
    "\n",
    "    # Sauvegarde toutes les stats affichés dans un fichier CSV.\n",
    "    pt.CSVLogger('logs/log.csv'),\n",
    "]\n",
    "\n",
    "model = pt.Model(net, optimizer, 'cross_entropy', batch_metrics=['accuracy'])\n",
    "model.cuda()\n",
    "\n",
    "history = model.fit_generator(train_loader, valid_loader, epochs=epoch, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois l'entraînement effectué, on peut aller lire le fichier de log CSV avec la librairie pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('logs/log.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étant donné le court entraînement, on devrait avoir obtenu des points de sauvegarde pour chacun des epochs. Amusez vous à charger différents epochs et à regarder l'impact sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('logs/best_epoch_4.ckpt')\n",
    "test_loss, test_acc = model.evaluate_generator(test_loader)\n",
    "print('Epoch 4: test_loss: {:.4f} test_acc: {:.2f}'.format(test_loss, test_acc))\n",
    "\n",
    "model.load_weights('logs/best_epoch_5.ckpt')\n",
    "test_loss, test_acc = model.evaluate_generator(test_loader)\n",
    "print('Epoch 5: test_loss: {:.4f} test_acc: {:.2f}'.format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
